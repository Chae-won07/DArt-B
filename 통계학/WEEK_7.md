# 통계학 7주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_7th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

7주차는 `2부-데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다


## Statistics_7th_TIL

### 2부. 데이터 분석 준비하기

### 11. 데이터 전처리와 파생변수 생성

<!-- 11.5 모델 성능 향상을 위한 파 변수 생성부터 11장 끝까지 진행해주시면 됩니다.-->

## Study ScheduleStudy Schedule

| 주차  | 공부 범위     | 완료 여부 |
| ----- | ------------- | --------- |
| 1주차 | 1부 p.2~46    | ✅         |
| 2주차 | 1부 p.47~81   | ✅         |
| 3주차 | 2부 p.82~120  | ✅         |
| 4주차 | 2부 p.121~167 | ✅         |
| 5주차 | 2부 p.168~202 | ✅         |
| 6주차 | 2부 p.203~250 | ✅         |
| 7주차 | 2부 p.251~299 | ✅         |

<!-- 여기까진 그대로 둬 주세요-->



---

# 1️⃣ 개념 정리 

## 11.데이터 전처리와 파생변수 생성

```
✅ 학습 목표 :
* 결측값과 이상치를 식별하고 적절한 방법으로 처리할 수 있다.
* 데이터 변환과 가공 기법을 학습하고 활용할 수 있다.
* 모델 성능 향상을 위한 파생 변수를 생성하고 활용할 수 있다.
```

### 11.5. 모델 성능 향상을 위한 파생 변수 생성

👉 **[파생 변수 생성]** 간단 요약 : 기존 변수를 조합하거나 변환하여 모델이 더 잘 학습할 수 있는 새로운 정보를 만들어내는 과정이다.

👉 **관련 개념 정리**
* <a>파생 변수</a> : 기존 변수를 조합하거나 변환해 모델 예측력을 높이기 위해 새로 만드는 변수이다.

* <a>변수 조합</a> : 평균, 비율, 합 등 여러 변수를 결합해 새로운 정보를 만드는 방식이다.

* <a>시계열 변화량</a> : 과거 값과 현재 값의 차이를 이용해 변화 패턴을 반영하는 파생 변수이다.

* <a>도메인 기반 범주화</a> : 연령을 연령대로 바꾸는 것처럼 비즈니스 의미에 맞게 변수를 재구성하는 방법이다.

* <a>다중공선성</a> : 변수들 간 상관성이 높아 예측 모델의 안정성이 떨어지는 문제로, 파생 변수 생성 시 주의가 필요하다.

* <a>PCA 활용</a> : 변수 간 중복 정보를 줄이기 위해 차원 축소를 사용하는 방법이다.

### 11.6. 슬라이딩 윈도우 데이터 가공

👉 **[슬라이딩 윈도우]** 간단 요약 : 시계열 데이터를 여러 기간으로 겹치게 분할하여 최근성을 반영하고 학습 데이터 양을 늘리는 기법이다.

👉 **관련 개념 정리**

* <a>최근성 확보</a> : 최근 데이터를 더 많이 반영해 예측 정확도를 높이는 데 목적이 있다.

* <a>관측치 증가</a> : 기간을 겹쳐 분할함으로써 같은 원본 데이터에서 더 많은 학습 데이터를 생성하는 효과이다.

* <a>데이터 확장</a> : 과거 여러 시점을 조합해 부족한 학습 데이터를 보완하는 방식이다.

### 11.7. 범주형 변수의 가변수 처리

👉 **[가변수 처리]** 간단 요약 : 범주형 변수를 모델이 계산할 수 있도록 0/1 형태의 숫자 변수로 변환하는 과정이며, 다중 범주일 경우 N−1개의 더미 변수를 생성한다.

👉 **관련 개념 정리**
* <a>가변수(Dummy variable)</a> : 범주형 변수를 0과 1로 표현한 숫자형 변수이다.

* <a>이진 범주 처리</a> : 두 개 범주(예: 남/여)는 하나의 가변수로 표현할 수 있다.

* <a>다중 범주 처리</a> : 세 개 이상 범주는 다중공선성을 피하기 위해 범주 개수보다 하나 적은 가변수를 생성한다.

* <a>기준선(Baseline)</a> : 제거된 한 범주로, 다른 범주의 효과를 비교하는 기준 역할을 한다.

### 11.8. 클래스 불균형 문제 해결을 위한 언더샘플링과 오버샘플링

👉 **[언더샘플링·오버샘플링]** 간단 요약 : 클래스 불균형 문제를 해결하기 위해 다수 클래스의 데이터를 줄이거나 소수 클래스를 늘려 비율을 균형 있게 맞추는 방법이다.

👉 **관련 개념 정리**
* <a>클래스 불균형</a> : 한 범주의 데이터가 다른 범주보다 지나치게 많은 상태로, 모델 성능 저하를 유발한다.

* <a>언더샘플링</a> : 다수 클래스의 데이터를 줄여 클래스 비율을 맞추는 방식이다.

* <a>랜덤 언더샘플링</a> : 다수 클래스 데이터를 무작위로 제거해 비율만 맞추는 단순한 접근법이다.

* <a>CNN(Condensed Nearest Neighbor)</a> : 소수 클래스와 유사한 다수 클래스만 남기도록 K-NN을 활용하는 언더샘플링 기법이다.

* <a>오버샘플링</a> : 소수 클래스의 데이터를 늘려 비율을 맞추는 방식이다.

* <a>랜덤 오버샘플링</a> : 소수 클래스의 데이터를 단순 복제하여 늘리는 방법이다.

* <a>SMOTE</a> : 소수 클래스 주변에서 새로운 가상의 데이터를 생성해 과적합을 줄이고 학습 효율을 높이는 기법이다.

### 11.9. 데이터 거리 측정 방법

👉 **[거리 측정 방법]** 간단 요약 : 관측치 간 유사성을 계산하기 위한 기준으로, k-NN 등 거리 기반 모델에서 사용되며 표준화·정규화를 통해 변수 간 단위 차이를 조정해야 한다.

👉 **관련 개념 정리**
* <a>거리 측정</a> : 데이터 간 유사성을 계산하는 기준으로, 거리 기반 모델에서 핵심 역할을 한다.

* <a>유클리드 거리</a> : 두 점 사이의 직선거리를 계산하는 가장 기본적인 거리 측정 방식이다.

* <a>표준화(Standardization)</a> : 평균 기준으로 데이터의 편차를 표준편차 단위로 환산하여 스케일을 맞추는 과정이다.

* <a>정규화(Normalization)</a> : 데이터 범위를 0~1 사이로 변환해 변수 간 크기 차이를 조정하는 방식이다.

* <a>거리 기반 모델</a> : K-NN, SVM 등 관측치 간 거리 계산을 기반으로 예측이나 분류를 수행하는 모델이다.

<br>
<br>

---

# 2️⃣ 확인 과제

> **교재에 있는 실습 파트를 직접 따라 해보세요. 실습을 완료한 뒤, 결과화면(캡처 또는 코드 결과)을 첨부하여 인증해 주세요.**
>
> **단순 이론 암기보다, 직접 손으로 따라해보면서 실습해 보는 것이 가장 확실한 학습 방법입니다.**
>
> > **인증 예시 : 통계 프로그램 결과, 시각화 이미지 캡처 등**

(1) 11.5 - 모델 성능 향상을 위한 파생 변수 생성
![alt text](images/WEEK_7_실습/(1).png)
(2) 11.6 - 슬라이딩 윈도우 데이터 가공
![alt text](images/WEEK_7_실습/(2).png)
(3) 11.7 - 범주형 변수의 가변수 처리
![alt text](images/WEEK_7_실습/(3).png)
(4) 11.8 - 클래스 불균형 문제 해결을 위한 언더샘플링과 오버샘플링
![alt text](images/WEEK_7_실습/(4).png)
(5) 11.9 - 데이터 거리 측정 방법
![alt text](images/WEEK_7_실습/(5).png)
~~~
인증 이미지가 없으면 과제 수행으로 인정되지 않습니다.
~~~



---

# 3️⃣ 실습 과제 (마지막 과제)

>  **🧚Q. 마지막 과제는 다음과 같습니다. 『데이터 분석가가 반드시 알아야 할 모든 것』 2부를 마무리하는 주차로,그동안 배운 데이터 전처리 및 파생변수 생성 내용을 실제 데이터에 적용해 보는 실습형 과제입니다. 단순히 함수를 실행하는 데서 그치지 않고, "왜 이 전처리 방법을 선택했는가" 와 "데이터가 말해주는 인사이트는 무엇인가'를 중심으로 EDA(탐색적 데이터 분석)를 함께 수행해주세요.**
>
> (정규과제 업로드 시트에 과제를 수행한 Git 링크와 코랩도 같이 올려주세요) 

<!-- 4주차 과제부터 실습하면서 배운 파이썬 문법을 적용하면서 실습을 진행해주세요 -->

~~~
과제 가이드라인

1. 실습 데이터셋 불러오기
Kaggle : Students Performance in Exams
- 출처: https://www.kaggle.com/datasets/spscientist/students-performance-in-exams
- 설명:
미국 고등학생 1000명의 성적과 배경 요인(성별, 인종, 부모 학력, 점심 여부, 시험 준비 과정 등)을 담은 데이터입니다.
math score, reading score, writing score 3가지 점수를 기준으로
학업 성취에 영향을 미치는 요인을 분석해볼 수 있습니다.

2. 데이터 전처리 진행하기
교재에서 배웠던 개념들을 적용해면서 전처리를 진행해봅시다. 
- 결측값 처리, 이상치 처리, 스케일링 등 
- (Optional) 범주형 변수 인코딩, 파생 변수 생성

3. EDA (탐색적 데이터 분석)
전처리된 데이터를 바탕으로 자유롭게 시각화 및 요약 분석을 수행하세요. 
- 점수 간 상관관계 분석
- 그룹 별 비교
- 여러 과정에 따른 성적 분포 비교
- 변수 간 관계 시각화 

4. 주석이나 코드 설명에서 들어가야 할 부분
- 교재에 있는 어떤 통계 개념을 적용했는지
- 각 개념이 데이터 분석에서 어떻게 활용되었는지를 스스로 설명해보세요.
- 단순한 코드 작성보다, 통계 개념 -> 코드 적용 -> 해석 -> 배운 점의 흐름을 명확히 드러내는 것이 핵심 기준입니다. 
~~~



<!-- 이것으로 통계학 정규과제가 마무리 되었습니다.  자료실에서 보면 아시겠지만, 이번 통계학 정규과제는 2부까지만 진행을 하였습니다. 3부부터는 모델에 대한 개념이 등장하기 때문에, 수학적 통계학을 배우고 분석의 기초를 다지는 부분에 여러분이 더 집중할 수 있도록 구성했습니다. 또한 전체 분량이 길기 때문에 학습 부담을 줄이기 위한 결정입니다. 따라서 이번 주차를 끝으로 정규 과제는 마무리되지만, 머신러닝 모델에 대해 더 깊이 공부하고 싶은 분들은 3부를 개인적으로 학습해보는 것을 추천드립니다. 그동안 과제를 열심히 하느라 고생하셨습니다. -->

### 🎉 수고하셨습니다.